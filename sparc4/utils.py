"""
    Created on Nov 28 2022

    Description: Library of useful recipes for the SPARC4 pipeline

    @author: Eder Martioli <emartioli@lna.br>

    Laboratório Nacional de Astrofísica - LNA/MCTI
    """

import os, sys
import glob
from copy import deepcopy

from astropy import units as u
from astropy.coordinates import AltAz, EarthLocation, SkyCoord
from astropy.io import fits
from astropy.time import Time, TimeDelta

import twirl
import matplotlib.pyplot as plt
from astropy.wcs import WCS
from astropy.wcs.utils import proj_plane_pixel_scales
import photutils
import numpy as np

import time
import signal
from functools import wraps

import logging

from astroquery.gaia import Gaia
from astroquery.simbad import Simbad


def clean_wcs_in_header(header) :
    
    """ Pipeline module to clean wcs keywords from fits header
    Parameters
    ----------
    header : fits.Header
        FITS image header

    Returns
        header : fits.Header
            Updated clean FITS image header
    -------
    """

    wcs_keywords_to_remove = ('WCSAXES', 'CRPIX',
                              'PC1', 'PC2', 'CDELT', 'CUNIT', 'CTYPE','CRVAL',
                              'LONPOLE','LATPOLE', 'MJDREF', 'RADESYS',
                              'A_', 'B_','AP_','BP_')
    
    for key in list(header.keys()):
        if key.startswith(wcs_keywords_to_remove) :
            del header[key]
            
    return header


def set_timecoords_keys(hdr, timezone=-3, timetype="", ra="", dec="",
                        set_airmass=True, time_key='DATE-OBS', exptimekey='EXPTIME',
                        longitude=-45.5825, latitude=-22.53444, altitude=1864):
    """ Pipeline module to set time and coordinates keywords
    Parameters
    ----------
    hdr : astropy.io.fits.Header
        FITS header unit to be updated
    timezone : int, optional
        Time zone of observations with respect to Greenwich.
        Default value is OPD's time zone of -3h
    timetype : str, optional
        if timetype=="LT" it will adopt time in the header as local time
    ra : str, optional
        string to overwrite header RA (Right Ascension) keyword
    dec : str, optional
        string to overwrite header DEC (Declination) keyword
    set_airmass : bool
        Calculate airmass and write it to the header
    time_key : str, optional
        string to point to the main date keyword in FITS header
    exptimekey : str, optional
        string to point to the exposure time (in units of s) keyword in FITS header
    longitude : float
        East longitude in degrees
    latitude : float
        North latitude in degrees
    altitude : float, optional
        altitude of observatory in meters

    Returns
    -------
    hdr : astropy.io.fits.Header
        FITS header unit to be updated
    """

    # Set geographic coordinates from header if they exist
    if 'OBSLONG' in hdr.keys():
        longitude = hdr['OBSLONG']
    if 'OBSLAT' in hdr.keys():
        latitude = hdr['OBSLAT']
    if 'OBSALT' in hdr.keys():
        altitude = hdr['OBSALT']  # hdr['OBSALT']

    observatory_location = EarthLocation.from_geodetic(lat=latitude, lon=longitude, height=altitude*u.m)

    # set equinox to 2000 or get it from header if it exists
    equinox = "J{:.1f}".format(2000.)
    if 'EQUINOX' in hdr.keys():
        equinox = "J{:.1f}".format(hdr['EQUINOX'])

    try:
        if 'RA' in  hdr.keys() :
            if ra == "" :
                ra = hdr['RA']
        else :
            ra = "00:00:00"
            
        if 'DEC' in  hdr.keys() :
            if dec == "" :
                dec = hdr['DEC']
        else :
            dec = "00:00:00"
        # set source observed
        source = SkyCoord(ra, dec, unit=(u.hourangle, u.deg),frame='icrs', equinox=equinox)
    except:
        print("WARNING: could not set coordinates RA: {}  DEC: {}. Setting RA=0 Dec=0.".format(ra, dec))
        source = SkyCoord(0, 0, unit="deg")

    radeg, decdeg = source.ra.value, source.dec.value
    # hdr.set("RA_DEG",radeg,"Requested Right Ascension (deg)")
    # hdr.set("DEC_DEG",decdeg,"Requested Declination (deg)")

    # try to set time from DATE-OBS keyword or try the patch if it doesn't work
    try:
        timestr = hdr[time_key]
        obstime = Time(timestr, format='isot', scale='utc', location=observatory_location)
    except:
        # patch for non-standard time format --> change back when headers generated by ACS is fixed
        timestr = "{}-{}-{}".format(hdr[time_key][:4], hdr[time_key][4:6], hdr[time_key][6:])
        obstime = Time(timestr, format='isot', scale='utc',location=observatory_location)

    hdr.set("DATE-OBS", timestr, "UT date at start of exposure ISOT")

    if timetype == "LT":
        print("INFO: setting time zone and applying it calculate local time")
        timeZone = TimeDelta(timezone*60*60, scale='tai', format='sec')
        #hdr.set("TIMEZONE",timezone,"time zone in hours e.g. BRT = UT - 3 hr")
        obstime = obstime - timeZone
        hdr.set("LTDATE", (obstime+timeZone).isot,"LT date at start of exposure ISOT")

    hdr.set("UTDATE", obstime.isot.split("T")[0], "UT date at start of exposure")
    hdr.set("UTTIME", obstime.isot.split("T")[1], "UT time at start of exposure")

    jd = obstime.jd
    mjd = obstime.mjd

    # Set light travel time for source observed
    ltt_bary = obstime.light_travel_time(source)
    bjd = obstime.tdb.jd + ltt_bary

    # HJD
    ltt_helio = obstime.light_travel_time(source, 'heliocentric')  # para o HJD
    hjd = obstime.tdb.jd + ltt_helio

    # get the exposure time from the header (in seconds) and convert it to days.
    exptime = get_exptime(hdr,exptimekey=exptimekey) / (24*60*60)

    # Compute the time at the middle of the exposure (i.e., halfway through exptime).
    midjd = obstime.jd + exptime/2
    midmjd = obstime.mjd + exptime/2
    midbjd = bjd.value + exptime/2
    midhjd = hjd.value + exptime/2

    hdr.set("JD", midjd, "Julian date at middle of exposure")
    hdr.set("MJD", midmjd, "Modified Julian date at middle of exposure")
    hdr.set("BJD", midbjd, "Barycentric Julian date at middle of exposure")
    hdr.set("HJD", midhjd, "Heliocentric Julian date at middle of exposure")

    hdr.set("STARTJD", jd, "Julian date at start of exposure")
    hdr.set("STARTMJD", mjd, "Modified Julian date at start of exposure")
    hdr.set("STARTBJD", bjd.value, "Barycentric Julian date at start of exposure")
    hdr.set("STARTHJD", hjd.value, "Heliocentric Julian date at start of exposure")

    # sidereal = obstime.sidereal_time('apparent')
    # hdr.set("ST",sidereal,"Sidereal time")
    # hdr.set("SD",sidereal,"Sidereal time")

    if set_airmass:
        # calculate airmass
        airmass = source.transform_to(AltAz(obstime=obstime, location=observatory_location)).secz
        hdr.set("AIRMASS", airmass.value, "Airmass at start of exposure")

    return hdr


def get_exptime(header, exptimekey="EXPTIME") :
    """ Pipeline module to get exposure time from header
    Parameters
    ----------
    header : astropy fits header
        header containing exptime
        
    exptimekey : str
        header keyword for exposure time
    Returns
    -------
    exptime : float
        exposure time in units of seconds
    """
    exptime = header[exptimekey]
    if type(exptime) == str:
        if ',' in exptime :
            exptime = exptime.replace(",", ".")
        exptime = float(exptime)
        
    return exptime


def identify_files(p, night, print_report=True):
    """ Pipeline module to identify SPARC4 files for reduction
    Parameters
    ----------
    p : dict
        dictionary to store pipeline parameters
    night : str
        Night directory name
    print_report : bool, optional
        Whether or not to print out the report

    Returns
    -------
    p : dict
        dictionary to store pipeline parameters
    """

    data_dir = p['ROOTDATADIR']
    channels = p['CHANNELS']

    inputdata = []
    data_directories = []

    for channel in channels:
        
        channeldir = '{}/{}/sparc4acs{}/'.format(data_dir, night, channel)
        channelpattern = '{}/{}/sparc4acs{}/*.fits'.format(data_dir, night, channel)
        if p['RAW_NIGTHS_INSIDE_CHANNELS_DIR'] :
            channeldir = '{}/sparc4acs{}/{}/'.format(data_dir, channel, night)
            channelpattern = '{}/sparc4acs{}/{}/*.fits'.format(data_dir, channel, night)

        inputdata.append(sorted(glob.glob(channelpattern)))

        data_directories.append(channeldir)

    objects, objsInPhot, objsInPolar = [], [], []
    obj_skycoords = []
    objectsdata, objsInPhotdata, objsInPolardata = [], [], []
    sciences, dflats, sflats, zeros = [], [], [], []
    darks, foci = [], []
    sciphot, scipolar = [], []
    scipolar_l2, scipolar_l4 = [], []
    objsInPolarL2, objsInPolarL4 = [], []
    objsInPolarL2data, objsInPolarL4data = [], []

    nimgs = 0

    for j in range(len(inputdata)):
        nimgs += len(inputdata[j])

        sflats.append([])
        dflats.append([])
        zeros.append([])
        darks.append([])
        foci.append([])
        sciences.append([])

        objects.append([])
        obj_skycoords.append([])

        objsInPhot.append([])
        objsInPolar.append([])

        objectsdata.append({})
        objsInPhotdata.append({})
        objsInPolardata.append({})

        sciphot.append([])
        scipolar.append([])

        scipolar_l2.append([])
        scipolar_l4.append([])
        objsInPolarL2.append([])
        objsInPolarL4.append([])

        objsInPolarL2data.append({})
        objsInPolarL4data.append({})

        for i in range(len(inputdata[j])):
            try :
                header = fits.getheader(inputdata[j][i])
            except :
                print("WARNING: could not open header. Skipping image: {} ".format(inputdata[j][i]))
                continue
                
            if header["OBSTYPE"] == p['OBJECT_OBSTYPE_KEYVALUE']:
                if "INSTMODE" in header.keys():
                    # print(j,i,inputdata[j][i]," has INSTMODE")
                    pass
                else:
                    print(j, i, inputdata[j][i], " doesn't have INSTMODE")
                    continue

                if header["OBJECT"] not in objects[j]:
                    objects[j].append(header["OBJECT"])
                    obj_skycoords[j].append([header["RA"],header["DEC"]])
                    
                    objectsdata[j][header["OBJECT"]] = []

                sciences[j].append(inputdata[j][i])
                objectsdata[j][header["OBJECT"]].append(inputdata[j][i])

                if header["INSTMODE"] == p['INSTMODE_PHOTOMETRY_KEYVALUE']:
                    if header["OBJECT"] not in objsInPhot[j]:
                        objsInPhot[j].append(header["OBJECT"])
                        objsInPhotdata[j][header["OBJECT"]] = []
                    sciphot[j].append(inputdata[j][i])
                    objsInPhotdata[j][header["OBJECT"]].append(inputdata[j][i])
                elif header["INSTMODE"] == p['INSTMODE_POLARIMETRY_KEYVALUE']:
                    if header["OBJECT"] not in objsInPolar[j]:
                        objsInPolar[j].append(header["OBJECT"])
                        objsInPolardata[j][header["OBJECT"]] = []
                    scipolar[j].append(inputdata[j][i])
                    objsInPolardata[j][header["OBJECT"]].append(
                        inputdata[j][i])

                    if header["WPSEL"] == 'L2':
                        if header["OBJECT"] not in objsInPolarL2[j]:
                            objsInPolarL2[j].append(header["OBJECT"])
                            objsInPolarL2data[j][header["OBJECT"]] = []
                        objsInPolarL2data[j][header["OBJECT"]].append(
                            inputdata[j][i])
                        scipolar_l2[j].append(inputdata[j][i])
                    elif header["WPSEL"] == 'L4':
                        if header["OBJECT"] not in objsInPolarL4[j]:
                            objsInPolarL4[j].append(header["OBJECT"])
                            objsInPolarL4data[j][header["OBJECT"]] = []
                        objsInPolarL4data[j][header["OBJECT"]].append(
                            inputdata[j][i])
                        scipolar_l4[j].append(inputdata[j][i])

            elif header["OBSTYPE"] == p['FLAT_OBSTYPE_KEYVALUE']:

                if header["OBSTYPE"] == 'SFLAT' or header["OBSTYPE"] == 'SKYFLAT' or header["OBJECT"] == 'SFLAT' or header["OBJECT"] == 'SKYFLAT':
                    sflats[j].append(inputdata[j][i])
                else:
                    dflats[j].append(inputdata[j][i])

            elif header["OBSTYPE"] == p['BIAS_OBSTYPE_KEYVALUE']:
                zeros[j].append(inputdata[j][i])

            elif header["OBSTYPE"] == p['DARK_OBSTYPE_KEYVALUE']:
                darks[j].append(inputdata[j][i])

            elif header["OBSTYPE"] == p['FOCUS_OBSTYPE_KEYVALUE']:
                foci[j].append(inputdata[j][i])

    p['data_directories'] = data_directories
    p['objects'] = objects
    p['obj_skycoords'] = obj_skycoords
    p['sciences'] = sciences
    p['dflats'] = dflats
    p['sflats'] = sflats
    p['zeros'] = zeros
    p['darks'] = darks
    p['foci'] = foci
    p['objsInPhot'], p['objsInPolar'] = objsInPhot, objsInPolar
    p['objectsdata'], p['objsInPhotdata'], p['objsInPolardata'] = objectsdata, objsInPhotdata, objsInPolardata
    p['sciphot'], p['scipolar'] = sciphot, scipolar
    p['scipolar_l2'], p['scipolar_l4'] = scipolar_l2, scipolar_l4
    p['objsInPolarl2'], p['objsInPolarl4'] = objsInPolarL2, objsInPolarL4
    p['objsInPolarL2data'], p['objsInPolarL4data'] = objsInPolarL2data, objsInPolarL4data

    ndflats, nsflats, nzeros, nsci = 0, 0, 0, 0
    ndarks, nfoci = 0, 0
    nsciphot, nscipolar, nscipolar_l2, nscipolar_l4 = 0, 0, 0, 0
    for j in range(len(channels)):
        ndflats += len(dflats[j])
        nsflats += len(sflats[j])
        nzeros += len(zeros[j])
        ndarks += len(darks[j])
        nfoci += len(foci[j])
        nsci += len(sciences[j])

        nsciphot += len(sciphot[j])
        nscipolar += len(scipolar[j])
        nscipolar_l2 += len(scipolar_l2[j])
        nscipolar_l4 += len(scipolar_l4[j])

    report_str = ""
    report_str += "***************************************\n"
    report_str += "********* Night: {} ***********\n".format(night)
    report_str += "***************************************\n"
    report_str += "Total number of images : {}\n".format(nimgs)
    for j in range(len(channels)):
        report_str += "Night dir: {}\n".format(data_directories[j])
        report_str += "\tNumber of images in channel {}: {}\n".format(channels[j], len(inputdata[j]))
        
    report_str += "---------------------------------------\n"
    report_str += "Total number of calibration images: {}\n".format(ndflats+nsflats+nzeros)
    report_str += "\tNumber of zero images: {}\n".format(nzeros)
    if nzeros:
        for j in range(len(channels)):
            report_str += "\t\t {} zero images in channel {}\n".format(len(zeros[j]), channels[j])

    report_str += "\tNumber of dome flat images: {}\n".format(ndflats)
    if ndflats:
        for j in range(len(channels)):
            report_str += "\t\t {} dome flat images in channel {}\n".format(len(dflats[j]), channels[j])

    report_str += "\tNumber of sky flat images: {}\n".format(nsflats)
    if nsflats:
        for j in range(len(channels)):
            report_str += "\t\t {} sky flat images in channel {}\n".format(len(sflats[j]), channels[j])

    report_str += "\tNumber of dark images: {}\n".format(ndarks)
    if ndarks:
        for j in range(len(channels)):
            report_str += "\t\t {} dark images in channel {}\n".format(len(darks[j]), channels[j])

    report_str += "\tNumber of focus images: {}\n".format(nfoci)
    if nfoci:
        for j in range(len(channels)):
            report_str += "\t\t {} focus images in channel {}\n".format(len(foci[j]), channels[j])

    report_str += "---------------------------------------\n"
    report_str += "Total number of science images: {}\n".format(nsci)
    if nsci:
        for j in range(len(channels)):
            report_str += "\t {} science images in channel {}\n".format(len(sciences[j]), channels[j])

    report_str += "\tTotal number of images in PHOT: {}\n".format(nsciphot)
    if nsciphot:
        for j in range(len(channels)):
            report_str += "\t\t {} PHOT images in channel {}\n".format(len(sciphot[j]), channels[j])

    report_str += "\tTotal number of images in POLAR: {}\n".format(nscipolar)
    if nscipolar:
        for j in range(len(channels)):
            report_str += "\t\t {} POLAR images in channel {}\n".format(len(scipolar[j]), channels[j])

    report_str += "\t\tNumber of POLAR images in L/2: {}\n".format(nscipolar_l2)
    if nscipolar_l2:
        for j in range(len(channels)):
            report_str += "\t\t\t {} POLAR L/2 images in channel {}\n".format(len(scipolar_l2[j]), channels[j])
    report_str += "\t\tNumber of POLAR images in L/4: {}\n".format(nscipolar_l4)
    if nscipolar_l4:
        for j in range(len(channels)):
            report_str += "\t\t\t {} POLAR L/4 images in channel {}\n".format(len(scipolar_l4[j]), channels[j])
    report_str += "---------------------------------------\n"
    for j in range(len(channels)):
        report_str += "Total number of objects observed in channel {}: {}\n".format(channels[j], len(objects[j]))

        for object in objects[j]:
            report_str += "\t{} has {} images in channel {}\n".format(object, len(objectsdata[j][object]), channels[j])

        report_str += "\t\t {} objects observed in PHOT \n".format(len(objsInPhot[j]))
            
        for object in objsInPhot[j]:
            report_str += "\t\t\t{} has {} images in PHOT\n".format(object, len(objsInPhotdata[j][object]))

        report_str += "\t\t {} objects observed in POLAR \n".format(len(objsInPolar[j]))
            
        for object in objsInPolar[j]:
            report_str += "\t\t\t{} has {} images\n".format(object, len(objsInPolardata[j][object]))

        report_str += "\t\t {} objects observed in POLAR L/2\n".format(len(objsInPolarL2[j]))
            
        for object in objsInPolarL2[j]:
            report_str += "\t\t\t{} has {} images\n".format(object, len(objsInPolarL2data[j][object]))

        report_str += "\t\t {} objects observed in POLAR L/4\n".format(len(objsInPolarL4[j]))
            
        for object in objsInPolarL4[j]:
            report_str += "\t\t\t{} has {} images\n".format(object, len(objsInPolarL4data[j][object]))
        report_str += "---------------------------------------\n"
    report_str += "***************************************\n"

    p["NIGHT_REPORT"] = report_str
    
    if print_report:
        print(report_str)
        
    return p


def safe_int_cast(s, default_value=None) :
    """
    Safely converts a string 's' to an integer.
    Returns a default value (or None) if the conversion fails.
    
    Parameters
    ----------
    s : str
        input string to cast into integer
    default_value : int
        default value to replace when convertion fails.
    """
    try:
        # int() automatically handles leading/trailing whitespaces
        return int(s)
    except (ValueError, TypeError):
        # Catch both ValueError (invalid literal) and TypeError (if input is not a string)
        print(f"Error: '{s}' is not a valid integer. Returning default value.")
        return default_value
        

def select_polar_sequences(list_of_files, sortlist=True, npos_in_seq=16, rolling_seq=False, nimages_per_seq_fixed=0, min_n_images_per_seq=4, verbose=False) :
    """ Pipeline module to select polarimetric sequences
    Parameters
    ----------
    list_of_files : list
        list of files
    sortlist : bool
        sort input list of files
    npos_in_seq : int
        to set number of waveplate positions in each sequence
    rolling_seq : bool
        switch to create rolling polar sequences, e.g. seqs[1234,2345,3456,4567,...]
    nimages_per_seq_fixed : int
        when given a number greater than the minimum number of images per sequence, it will adopt a fixed number of images per sequence
    min_n_images_per_seq : int
        minimum allowed number of images per sequence
    verbose : bool
        turn on verbose

    Returns
    -------
    sequences : list
        list of sequences, where each sequence is a list of files
    """

    sortedlist = deepcopy(list_of_files)
    if sortlist:
        # make sure the input list is sorted
        sortedlist = sorted(sortedlist)

    # initialize list of sequences
    sequences = []

    # run only for a non-empty list
    if len(sortedlist):
    
        # when a valid fixed number of images per sequence is given
        if nimages_per_seq_fixed >= min_n_images_per_seq :
            # if the number of images per seq is greater than the total number of images, do 1 sequence only
            if nimages_per_seq_fixed > len(sortedlist) :
                sequences.append(sortedlist)
            else  :
                ns = len(sortedlist) - nimages_per_seq_fixed + 1
                for i in range(ns) :
                    if rolling_seq :
                        sequences.append(sortedlist[i:i+nimages_per_seq_fixed])
                    else :
                        first_index = i*nimages_per_seq_fixed
                        last_index = i*nimages_per_seq_fixed + nimages_per_seq_fixed
                        if last_index > len(sortedlist) :
                            last_index = len(sortedlist)
                        tmp_seq = sortedlist[first_index:last_index]
                        if len(tmp_seq) >= min_n_images_per_seq :
                            sequences.append(tmp_seq)
        else :
            # save WPPOS of first image
            prev_pos = safe_int_cast(fits.getheader(sortedlist[0])['WPPOS'], default_value=None)
                        
            block_index = 0
            blocks, block_pos = [], []
            blocks.append([])
            
            blocks[block_index].append(sortedlist[0])
            block_pos.append(prev_pos)
                    
            for i in range(1,len(sortedlist)) :
                # save WPPOS of first image
                pos = safe_int_cast(fits.getheader(sortedlist[0])['WPPOS'], default_value=None)
                
                if pos != prev_pos :
                    prev_pos = pos
                    block_index += 1
                    blocks.append([])
                    block_pos.append(prev_pos)
                    
                blocks[block_index].append(sortedlist[i])
              
            number_of_blocks = len(block_pos)
            sequences.append([])
            blocksinseq = []
            seq_index = 0

            if rolling_seq :
                
                for j in range(len(block_pos)) :
                    pos_in_seq = []
                    
                    lastjj = j + npos_in_seq
                    
                    if lastjj > len(block_pos) :
                        lastjj = len(block_pos)
                    
                    for jj in range(j,lastjj) :
                        if block_pos[jj] not in pos_in_seq :
                            for i in range(len(blocks[jj])) :
                                sequences[seq_index].append(blocks[jj][i])
                            pos_in_seq.append(block_pos[jj])
                                                        
                    blocksinseq.append(len(pos_in_seq))
                    
                    if lastjj == len(block_pos) :
                        break

                    sequences.append([])
                    seq_index += 1
                    
            else :
                nblocks_in_sequence = 0
            
                #--
                prev_block_pos = block_pos[0]
                for i in range(len(blocks[0])) :
                    sequences[seq_index].append(blocks[0][i])
                nblocks_in_sequence += 1
                #--
                
                for j in range(1,len(block_pos)) :
        
                    # reset sequence
                    if nblocks_in_sequence == npos_in_seq or block_pos[j] < prev_block_pos :
                        sequences.append([])
                        seq_index += 1
                        blocksinseq.append(nblocks_in_sequence)
                        nblocks_in_sequence = 0
                        
                    #--
                    prev_block_pos = block_pos[j]
                    for i in range(len(blocks[j])) :
                        sequences[seq_index].append(blocks[j][i])
                    nblocks_in_sequence += 1
                    if j==len(block_pos)-1:
                        blocksinseq.append(nblocks_in_sequence)
                    #--
                
            if verbose :
                for k in range(len(sequences)) :
                    print("Sequence {} of {} : {} files for {} waveplate positions".format(k+1,len(sequences),len(sequences[k]),blocksinseq[k]))
                
    return sequences



def select_fits_files_with_keyword(list_of_files, keyword, value):

    """ Pipeline tool to select FITS files matching a given keyword value
    Parameters
    ----------
    list_of_files : list
        input list of files
    keyword : str
        FITS keyword to match
    value : *
        keyword value to compare and match selected files

    Returns
    -------
    matching_files : list
        list of files
    """

    matching_files = []
    
    for i in range(len(list_of_files)):
        if list_of_files[i].endswith(".fits"):
            # Open the FITS file and read the header
            with fits.open(list_of_files[i]) as hdul:
                header = hdul[0].header
                # Check if the keyword exists and matches the desired value
                if keyword in header and header[keyword] == value:
                    matching_files.append(list_of_files[i])
    
    return matching_files


def check_astrometry(filename, fov_search_factor=2.0, apply_sparsify_filter=False, sparsify_factor=0.01, nsources_to_plot=30) :

    """ Pipeline module to calcualte astrometric solution from an existing wcs
    Parameters
    ----------
    filename : str
        fits file name

    Returns
        wcs : astropy.wcs.WCS

    -------
    """

    # load fits image
    hdul = fits.open(filename)
    img_data, hdr = hdul[0].data, hdul[0].header
    
    #print(repr(hdr))
    
    # load wcs from input header
    w = WCS(hdr,naxis=2)
    
    fov = (img_data.shape * proj_plane_pixel_scales(w))[0]
    center = w.pixel_to_world(*np.array(img_data.shape) / 2)
    
    # get RAs and Decs from Gaia catalog for a sky area of 2 x FoV
    gaia_sources_skycoords = twirl.gaia_radecs(center, fov_search_factor * fov)
    
    # we only keep stars 0.01 degree apart from each other
    if apply_sparsify_filter :
        gaia_sources_skycoords = twirl.geometry.sparsify(gaia_sources_skycoords, sparsify_factor)
    
    # use input wcs to generate a "guess" for the set of pixel coordinates of Gaia sources
    gaia_sources_pixcoords = np.array(w.world_to_pixel_values(gaia_sources_skycoords))
    
    plt.imshow(img_data, vmin=np.median(img_data), vmax=3 * np.median(img_data), cmap="Greys_r")
    _ = photutils.aperture.CircularAperture(gaia_sources_pixcoords[:nsources_to_plot], r=10.0).plot(color="y")
    plt.show()

    return w


def timeout(timeout_secs: int):
    """ Pipeline decorator to apply a timeout in a function call
    Parameters
    ----------
    timeout_secs : int
        define time out in seconds

    Returns
    -------
    wrapper :
    
    """

    def wrapper(func):
        @wraps(func)
        def time_limited(*args, **kwargs):
            # Register an handler for the timeout
            def handler(signum, frame):
                raise Exception(f"Timeout for function '{func.__name__}'")

            # Register the signal function handler
            signal.signal(signal.SIGALRM, handler)

            # Define a timeout for your function
            signal.alarm(timeout_secs)

            result = None
            try:
                result = func(*args, **kwargs)
            except Exception as exc:
                raise exc
            finally:
                # disable the signal alarm
                signal.alarm(0)

            return result

        return time_limited

    return wrapper


def start_logger(file_name="") :

    """ Pipeline function to start logger
    Parameters
    ----------
    file_name : str
        define output logger file name

    Returns
    -------
    logger : Logger object
    
    """

    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')

    stdout_handler = logging.StreamHandler(sys.stdout)
    #stdout_handler.setLevel(logging.DEBUG)
    stdout_handler.setFormatter(formatter)
    logger.addHandler(stdout_handler)

    if file_name != "" :
        file_handler = logging.FileHandler(file_name)
        #file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    
    return logger



def gaiadr3_query(ra, dec,
                  radius=5.,
                  max_nsrcs=1000,
                  fields="source_id, ra, dec, parallax, pmra, pmdec, phot_g_mean_mag, phot_bp_mean_mag, phot_rp_mean_mag") :

    """ Pipeline function to perform a query of Gaia sources within a circular sky region of a given radius
    Parameters
    ----------
    ra : float
        right ascention of the center of the field in degrees
    dec : float
        declination of the center of the field in degrees
    radius : float
        search radius in arcmin
    max_nsrcs : int
        maximum number of sources to return, sorted by magnitude
    fields : str
        fields to be returned in output table. WARNING: use only column names of Gaia DR3 table

    Returns
    -------
    gaia_tbl : astropy.table.table.Table
        output table of Gaia DR3 sources
        
    """

    radius_deg = radius/60.

    meta = Gaia.load_table('gaiadr3.gaia_source')

    query = f"""SELECT
                TOP {max_nsrcs}
                {fields}
                FROM gaiadr3.gaia_source AS gaia
                WHERE 1=CONTAINS(
                    POINT('ICRS', {ra}, {dec}),
                    CIRCLE('ICRS', gaia.ra, gaia.dec, {radius_deg}))
                ORDER BY gaia.phot_g_mean_mag
            """
    if max_nsrcs < 2000 :
        job = Gaia.launch_job(query)
    else :
        job = Gaia.launch_job_async(query)
        
    gaia_tbl = job.get_results()
    
    return gaia_tbl


def match_object_with_simbad(obj_id, ra=None, dec=None, search_radius_arcsec=10) :

    """ Module to match a given object id with Simbad
    Parameters
    ----------
    objprods: dict
        data container to store products
    ra: float (optional)
        right ascension (deg)
    dec: float (optional)
        declination (deg)
    search_radius_arcsec: float
        search radius in units of arcseconds
    Returns
        obj_match_simbad, coord: simbad_entry, SkyCoord()
    -------
    """

    obj_match_simbad, coord = None, None
    
    try :
        print("Querying SIMBAD database to match object ID={}".format(obj_id))
        # query SIMBAD repository to match object by ID
        obj_match_simbad = Simbad.query_object(obj_id)
    except :
        if ra is not None and dec is not None :
            print("Querying SIMBAD database to match an object at RA={} DEC={}".format(ra, dec))
            # cast input coordinates into SkyCoord
            coord = SkyCoord(ra, dec, unit=(u.deg, u.deg), frame='icrs')
            # query SIMBAD repository to match an object by coordinates
            obj_match_simbad = Simbad.query_region(coord, radius = search_radius_arcsec * (1./3600.) * u.deg)
        else :
            print("WARNING: could not find Simbad match for object {}".format(obj_id))

    if obj_match_simbad is not None :
        ra = obj_match_simbad["RA"][0]
        dec = obj_match_simbad["DEC"][0]
    
        # cast coordinates into SkyCoord
        coord = SkyCoord(ra, dec, unit=(u.hourangle, u.deg), frame='icrs')

    return obj_match_simbad, coord
